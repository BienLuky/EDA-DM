import argparse

def cifar_get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="configs/cifar10.yml", help="Path to the config file")
    parser.add_argument("--seed", type=int, default=1234, help="Random seed")
    parser.add_argument("--logdir",type=str, default="result/cifar", help="extra logdir")
    parser.add_argument("--use_pretrained", default=True, action="store_true")
    parser.add_argument("--sample_type",type=str, default="generalized", help="sampling approach (generalized or ddpm_noisy)",)
    parser.add_argument("--skip_type",type=str, default="quad", help="skip according to (uniform or quadratic)",)
    parser.add_argument("--timesteps", type=int, default=100, help="number of steps involved")
    parser.add_argument("--eta",type=float, default=0.0, help="eta used to control the variances of sigma",)
    parser.add_argument("--sequence", action="store_true")
    parser.add_argument("--ptq", default=True, action="store_true", help="apply post-training quantization")
    parser.add_argument("--quant_act", default=True, action="store_true", help="if to quantize activations when ptq==True")
    parser.add_argument("--weight_bit",type=int, default=4, help="int bit for weight quantization",)
    parser.add_argument("--act_bit",type=int, default=8, help="int bit for activation quantization",)
    parser.add_argument("--quant_mode", type=str, default="qdiff",  choices=["qdiff"],  help="quantization mode to use")
    parser.add_argument("--max_images", type=int, default=50000, help="number of images to sample")

    # qdiff specific configs
    parser.add_argument("--device", type=str, default="cuda:0", help="path for calibrated model ckpt")
    parser.add_argument("--a_sym", default=False, action="store_true", help="act quantizers use symmetric quantization")
    parser.add_argument("--sm_abit",type=int, default=8, help="attn softmax activation bit")
    parser.add_argument("--split", default=True, action="store_true", help="split shortcut connection into two parts")
    parser.add_argument("--verbose", action="store_true", help="print out info like quantized model arch")
    parser.add_argument("--calib_num_samples", default=1024, type=int, help="size of the calibration dataset",)
    parser.add_argument("--batch_samples", default=1024, type=int, help="size of the sample dataset",)
    parser.add_argument("--class_cond", action="store_true", help="class difusion")
    parser.add_argument("--recon", default=True, action="store_true", help="use reconstruction")
    parser.add_argument("--block_recon", default=True, action="store_true", help="use block reconstruction")
    parser.add_argument("--layer_recon", action="store_true", help="use layer reconstruction")
    parser.add_argument("--add_loss", type=float, default=0.8, help="hyperparameter to balance block loss and layers losses")
    parser.add_argument("--lr_w", type=float, default=5e-1, help="learn ratio to weight")
    parser.add_argument("--lr_a", type=float, default=5e-4, help="learn ratio to act")
    parser.add_argument("--lamda", type=float, default=1.2, help="hyperparameter to balance D score and V score")
    return parser



def bedroom_get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("--resume", type=str, default="models/ldm/lsun_beds256/model.ckpt", help="load from logdir or checkpoint in logdir",)
    parser.add_argument("--n_samples", type=int, help="number of samples to draw", default=50000)
    parser.add_argument("--eta", type=float, help="eta for ddim sampling (0.0 yields deterministic sampling)", default=1.0)
    parser.add_argument("--vanilla_sample", default=False, action='store_true', help="vanilla sampling (default option is DDIM sampling)?",)
    parser.add_argument("--seed", type=int, default=1234, help="the seed (for reproducible sampling)",)
    parser.add_argument("--logdir", type=str, help="extra logdir", default="result/bedroom")
    parser.add_argument("--dataset", type=str, help="evaluation logdir", default="/dataset/LSUN/bedrooms/train_1000k")
    parser.add_argument("--custom_steps", type=int, help="number of steps for ddim and fastdpm sampling", default=200)
    parser.add_argument("--batch_size", type=int, help="the bs", default=50)
    
    # linear quantization configs
    parser.add_argument("--ptq", default=True, action="store_true", help="apply post-training quantization")
    parser.add_argument("--split", default=True, action="store_true",help="split shortcut connection into two parts")
    parser.add_argument("--quant_act", default=True, action="store_true", help="if to quantize activations when ptq==True")
    parser.add_argument("--weight_bit",type=int,default=4,help="int bit for weight quantization",)
    parser.add_argument("--act_bit",type=int,default=8, help="int bit for activation quantization",)
    parser.add_argument("--quant_mode", type=str, default="qdiff", choices=["qdiff"], help="quantization mode to use")
    parser.add_argument("--device", type=str, default="cuda:0", help="path for calibrated model ckpt")
    parser.add_argument("--a_sym", default=False, action="store_true", help="act quantizers use symmetric quantization")
    parser.add_argument("--sm_abit",type=int, default=8, help="attn softmax activation bit")
    parser.add_argument("--dpm", action="store_true", help="use dpm solver for sampling")
    parser.add_argument("--verbose", action="store_true", help="print out info like quantized model arch")
    parser.add_argument("--calib_num_samples", default=1024, type=int, help="size of the calibration dataset",)
    parser.add_argument("--batch_samples", default=64, type=int, help="size of the sample dataset",)
    parser.add_argument("--class_cond", action="store_true", help="class difusion")
    parser.add_argument("--recon", default=True, action="store_true", help="use reconstruction")
    parser.add_argument("--add_loss", type=float, default=0.001, help="hyperparameter to balance block loss and layers losses")
    parser.add_argument("--lr_w", type=float, default=1e-2, help="learn ratio to weight")
    parser.add_argument("--lr_a", type=float, default=5e-3, help="learn ratio to act")
    parser.add_argument("--lamda", type=float, default=100.0, help="hyperparameter to balance D score and V score")
    return parser

def church_get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("--resume", type=str, help="load from logdir or checkpoint in logdir",)
    parser.add_argument("--n_samples", type=int, help="number of samples to draw", default=50000)
    parser.add_argument("--eta", type=float, help="eta for ddim sampling (0.0 yields deterministic sampling)", default=0.0)
    parser.add_argument("--vanilla_sample", default=False, action='store_true', help="vanilla sampling (default option is DDIM sampling)?",)
    parser.add_argument("--seed", type=int, default=1234, help="the seed (for reproducible sampling)",)
    parser.add_argument("--logdir", type=str, help="extra logdir", default="result/church")
    parser.add_argument("--dataset", type=str, help="evaluation logdir", default="/dataset/LSUN/churchs/train_new")
    parser.add_argument("--custom_steps", type=int, help="number of steps for ddim and fastdpm sampling", default=500)
    parser.add_argument("--batch_size", type=int, help="the bs", default=100)
    
    # linear quantization configs
    parser.add_argument("--ptq", default=True, action="store_true", help="apply post-training quantization")
    parser.add_argument("--split", default=True, action="store_true", help="split shortcut connection into two parts")
    parser.add_argument("--quant_act", default=True, action="store_true", help="if to quantize activations when ptq==True")
    parser.add_argument("--weight_bit", type=int, default=4, help="int bit for weight quantization",)
    parser.add_argument("--act_bit", type=int, default=8, help="int bit for activation quantization",)
    parser.add_argument("--quant_mode", type=str, default="qdiff", choices=["qdiff"], help="quantization mode to use")
    parser.add_argument("--device", type=str, default="cuda:0", help="path for calibrated model ckpt")
    parser.add_argument("--a_sym", default=False, action="store_true", help="act quantizers use symmetric quantization")
    parser.add_argument("--sm_abit",type=int, default=8, help="attn softmax activation bit")
    parser.add_argument("--dpm", action="store_true", help="use dpm solver for sampling")
    parser.add_argument("--verbose", action="store_true", help="print out info like quantized model arch")
    parser.add_argument("--calib_num_samples", default=1024, type=int, help="size of the calibration dataset",)
    parser.add_argument("--batch_samples", default=64, type=int, help="size of the sample dataset",)
    parser.add_argument("--class_cond", action="store_true", help="class difusion")
    parser.add_argument("--recon", default=True, action="store_true", help="use reconstruction")
    parser.add_argument("--add_loss", type=float, default=1.0, help="hyperparameter to balance block loss and layers losses")
    parser.add_argument("--lr_w", type=float, default=5e-2, help="learn ratio to weight")
    parser.add_argument("--lr_a", type=float, default=1e-4, help="learn ratio to act")
    parser.add_argument("--lamda", type=float, default=1.0, help="hyperparameter to balance D score and V score")
    return parser

def imagenet_get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("--logdir", type=str, help="extra logdir", default="result/imagenet")
    parser.add_argument("--dataset", type=str, help="evaluation logdir", default="/dataset/imagenet/train_resize")
    parser.add_argument("--skip_grid", default=True, action='store_true', help="do not save a grid, only individual samples. Helpful when evaluating lots of samples",)
    parser.add_argument("--skip_save", action='store_true', help="do not save individual samples. For speed measurements.",)
    parser.add_argument("--custom_steps", type=int, default=20, help="number of ddim sampling steps",)
    parser.add_argument("--ddim_eta", type=float, default=0.0, help="ddim eta (eta=0.0 corresponds to deterministic sampling",)
    parser.add_argument("--n_samples", type=int, default=50000, help="how many samples to produce for each given prompt. A.k.a. batch size",)
    parser.add_argument("--n_batch", type=int, default=50, help="how many samples to produce for each given prompt. A.k.a. batch size",)
    parser.add_argument("--n_rows", type=int, default=0, help="rows in the grid (default: n_samples)",)
    parser.add_argument("--scale", type=float, default=3.0, help="unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))",)
    parser.add_argument("--config", type=str, default="configs/latent-diffusion/cin256-v2.yaml", help="path to config which constructs model",)
    parser.add_argument("--ckpt", type=str, default="models/ldm/cin256/model.ckpt", help="path to checkpoint of model",)
    parser.add_argument("--seed", type=int, default=1234, help="the seed (for reproducible sampling)",)
    parser.add_argument("--precision", type=str, help="evaluate at this precision", choices=["full", "autocast"], default="autocast")
    parser.add_argument("--cond", default=True, action="store_true", help="whether to use conditional guidance")
    parser.add_argument("--no_grad_ckpt", default=True, action="store_true", help="disable gradient checkpointing")

    # linear quantization configs
    parser.add_argument("--ptq", default=True, action="store_true", help="apply post-training quantization")
    parser.add_argument("--quant_act", default=True, action="store_true",  help="if to quantize activations when ptq==True")
    parser.add_argument("--weight_bit", type=int, default=4, help="int bit for weight quantization",)
    parser.add_argument("--act_bit", type=int, default=8, help="int bit for activation quantization",)
    parser.add_argument("--quant_mode", type=str, default="qdiff", choices=["linear", "squant", "qdiff"], help="quantization mode to use")
    parser.add_argument("--device", type=str, default="cuda:0", help="path for calibrated model ckpt")
    parser.add_argument("--split", default=True, action="store_true", help="use split strategy in skip connection")
    parser.add_argument("--a_sym", default=False, action="store_true", help="act quantizers use symmetric quantization")
    parser.add_argument("--sm_abit",type=int, default=8, help="attn softmax activation bit")
    parser.add_argument("--verbose", action="store_true", help="print out info like quantized model arch")
    parser.add_argument("--calib_num_samples", default=1024, type=int, help="size of the calibration dataset",)
    parser.add_argument("--batch_samples", default=64, type=int, help="size of the sample dataset",)
    parser.add_argument("--recon", default=True, action="store_true", help="use reconstruction")
    parser.add_argument("--add_loss", type=float, default=1.3, help="hyperparameter to balance block loss and layers losses")
    parser.add_argument("--lr_w", type=float, default=5e-1, help="learn ratio to weight")
    parser.add_argument("--lr_a", type=float, default=1e-4, help="learn ratio to act")
    parser.add_argument("--lamda", type=float, default=0.5, help="hyperparameter to balance D score and V score")
    return parser


def coco_get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument("--prompt", type=str, default="a painting of a virus monster playing guitar", help="the prompt to render")
    parser.add_argument("--logdir", type=str, help="extra logdir", default="result/coco")
    parser.add_argument("--dataset", type=str, help="evaluation logdir", default="/dataset/coco2014/val2014_resize")
    parser.add_argument("--skip_grid", default=True, action='store_true', help="do not save a grid, only individual samples. Helpful when evaluating lots of samples",)
    parser.add_argument("--skip_save", action='store_true', help="do not save individual samples. For speed measurements.",)
    parser.add_argument("--custom_steps", type=int, default=50, help="number of ddim sampling steps",)
    parser.add_argument("--plms", default=True, action='store_true', help="use plms sampling",)
    parser.add_argument("--fixed_code", action='store_true', help="if enabled, uses the same starting code across samples ",)
    parser.add_argument("--ddim_eta", type=float, default=0.0, help="ddim eta (eta=0.0 corresponds to deterministic sampling",)
    parser.add_argument("--n_iter", type=int, default=1, help="sample this often",)
    parser.add_argument("--H", type=int, default=512, help="image height, in pixel space",)
    parser.add_argument("--W", type=int, default=512, help="image width, in pixel space",)
    parser.add_argument("--C", type=int, default=4, help="latent channels",)
    parser.add_argument("--f", type=int, default=8, help="downsampling factor",)
    parser.add_argument("--n_samples", type=int, default=10000, help="how many samples to produce for each given prompt. A.k.a. batch size",)
    parser.add_argument("--n_batch", type=int, default=4,  help="how many samples to produce for each given prompt. A.k.a. batch size",)
    parser.add_argument("--n_rows",  type=int, default=0, help="rows in the grid (default: n_samples)",)
    parser.add_argument("--scale", type=float, default=7.5, help="unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))",)
    parser.add_argument("--from-file", type=str, help="if specified, load prompts from this file",)
    parser.add_argument("--config", type=str, default="configs/stable-diffusion/v1-inference.yaml",  help="path to config which constructs model",)
    parser.add_argument("--ckpt", type=str, default="models/ldm/stable-diffusion-v1/model.ckpt", help="path to checkpoint of model",)
    parser.add_argument("--seed", type=int, default=1234, help="the seed (for reproducible sampling)",)
    parser.add_argument("--precision", type=str, help="evaluate at this precision", choices=["full", "autocast"], default="autocast")
    parser.add_argument( "--device", type=str, default="cuda:0",  help="path for calibrated model ckpt")
    parser.add_argument("--cond", default=True, action="store_true", help="whether to use conditional guidance")
    parser.add_argument("--no_grad_ckpt", default=True, action="store_true", help="disable gradient checkpointing")

    # linear quantization configs
    parser.add_argument("--ptq", default=True, action="store_true", help="apply post-training quantization")
    parser.add_argument("--quant_act", default=True, action="store_true", help="if to quantize activations when ptq==True")
    parser.add_argument("--weight_bit", type=int, default=4, help="int bit for weight quantization",)
    parser.add_argument("--act_bit", type=int, default=8, help="int bit for activation quantization",)
    parser.add_argument("--quant_mode", type=str, default="qdiff", choices=["linear", "squant", "qdiff"], help="quantization mode to use")

    # qdiff specific configs
    parser.add_argument("--split", default=True, action="store_true",  help="use split strategy in skip connection")
    parser.add_argument("--a_sym", default=False, action="store_true", help="act quantizers use symmetric quantization")
    parser.add_argument("--sm_abit",type=int, default=8, help="attn softmax activation bit")
    parser.add_argument("--verbose", action="store_true", help="print out info like quantized model arch")
    parser.add_argument("--calib_num_samples", default=256, type=int, help="size of the calibration dataset",)
    parser.add_argument("--batch_samples", default=8,  type=int, help="size of the sample dataset",)
    parser.add_argument("--recon", default=True, action="store_true", help="use reconstruction")
    parser.add_argument("--add_loss", type=float, default=0.5, help="hyperparameter to balance block loss and layers losses")
    parser.add_argument("--lr_w", type=float, default=3e-2, help="learn ratio to weight")
    parser.add_argument("--lr_a", type=float, default=1e-4, help="learn ratio to act")
    parser.add_argument("--lamda", type=float, default=50.0, help="hyperparameter to balance D score and V score")
    return parser